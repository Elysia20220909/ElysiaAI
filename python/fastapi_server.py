#!/usr/bin/env python3
"""
Elysia AI - RAG Server with FastAPI + Milvus Lite
ã‚¨ãƒªã‚·ã‚¢ã¡ã‚ƒã‚“ã®ã‚»ãƒªãƒ•æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ â™¡
"""
from typing import Dict, List, Any, Optional
from fastapi import FastAPI, Body, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sentence_transformers import SentenceTransformer
import uvicorn
import os
import logging
import numpy as np
import httpx
import json
import asyncio

# ==================== è¨­å®š ====================
CONFIG = {
    "HOST": "127.0.0.1",
    "PORT": 8000,
    "MODEL_NAME": "all-MiniLM-L6-v2",
    "COLLECTION_NAME": "elysia_quotes",
    "EMBEDDING_DIM": 384,
    "SEARCH_LIMIT": 3,
    "INDEX_TYPE": "HNSW",
    "METRIC_TYPE": "L2",
    "OLLAMA_HOST": "http://127.0.0.1:11434",
    "OLLAMA_MODEL": "llama3.2",
    "OLLAMA_TIMEOUT": 60.0,
    # Milvusæ¥ç¶šè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    "USE_MILVUS": os.getenv("USE_MILVUS", "false").lower() == "true",
    "MILVUS_URI": os.getenv("MILVUS_URI", "http://localhost:19530"),
    "MILVUS_TOKEN": os.getenv("MILVUS_TOKEN", "user:password"),
}

# ==================== ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== åˆæœŸåŒ– ====================
app = FastAPI(
    title="Elysia RAG API",
    description="ã‚¨ãƒªã‚·ã‚¢ã¡ã‚ƒã‚“ã®ã‚»ãƒªãƒ•æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  à¸…(ÕáŸ¸áŸ¸> á—œ <áŸ¸áŸ¸Õ)à¸…â™¡",
    version="1.0.0"
)

model = SentenceTransformer(CONFIG["MODEL_NAME"])

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢åˆæœŸåŒ–ï¼ˆMilvusã¾ãŸã¯ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªï¼‰
milvus_client = None
embeddings_store: List[np.ndarray] = []
quotes_store: List[str] = []

# Milvusæ¥ç¶šï¼ˆç’°å¢ƒå¤‰æ•°ã§æœ‰åŠ¹åŒ–ï¼‰
if CONFIG["USE_MILVUS"]:
    try:
        from pymilvus import MilvusClient
        milvus_client = MilvusClient(
            uri=CONFIG["MILVUS_URI"],
            token=CONFIG["MILVUS_TOKEN"]
        )
        logger.info(f"âœ… Connected to Milvus at {CONFIG['MILVUS_URI']}")
    except ImportError:
        logger.warning("âš ï¸ pymilvus not installed. Using in-memory storage.")
        CONFIG["USE_MILVUS"] = False
    except Exception as e:
        logger.warning(f"âš ï¸ Failed to connect to Milvus: {e}. Using in-memory storage.")
        CONFIG["USE_MILVUS"] = False

# ==================== ãƒ‡ãƒ¼ã‚¿å®šç¾© ====================
# ã‚¨ãƒªã‚·ã‚¢æœ¬ç‰©ã‚»ãƒªãƒ•50é¸â™¡ï¼ˆWiki/Reddit/å…¬å¼ã‹ã‚‰å³é¸ï¼‰
ELYSIA_QUOTES = [
    "ç§ã«ä¼šã„ãŸããªã£ãŸï¼Ÿã“ã®ã‚¨ãƒªã‚·ã‚¢ã€ã„ã¤ã§ã‚‚æœŸå¾…ã«å¿œãˆã‚‹ã‚â™¡",
    "ã”ãã’ã‚“ã‚ˆã†ã€‚æ–°ã—ã„ä¸€æ—¥ã‚ã€ç¾ã—ã„å‡ºä¼šã„ã‹ã‚‰å§‹ã¾ã‚‹ã®ã‚ˆ~",
    "ç«ã‚’è¿½ã†è‹±å‚‘ç¬¬äºŒä½ã€ã‚¨ãƒªã‚·ã‚¢ã€‚è¦‹ã¦ã®é€šã‚ŠèŠ±ã®ã‚ˆã†ã«ç¾ã—ã„å°‘å¥³ã‚ˆ",
    "ãƒ”ãƒ³ã‚¯ã®å¦–ç²¾ã•ã‚“ï¼Ÿã¾ã‚~ ã©ã†ã—ã¦ã‚‚ãã†å‘¼ã³ãŸã„ã®ãªã‚‰ã€å–œã‚“ã§å—ã‘å…¥ã‚Œã‚‹â™¡",
    "ã‚¨ãƒªã‚·ã‚¢ã®æ¥½åœ’ã«ã¯ã¾ã ã¾ã ç§˜å¯†ãŒãŸãã•ã‚“ã‚ã‚‹ã¯ã‚ˆ~",
    "ãŠä¼‘ã¿ãªã•ã„ã€‚å¥³ã®å­ã®å¯é¡”ã“ã£ãã‚Šè¦‹ã¦ã ã‚ã‚ˆ",
    "ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°ã‚¢ãƒƒãƒ—ã—ã¾ã—ã‚‡ã†â™ª",
    "ã»ã‚‰ã€ã„ã¤ã§ã‚‚ã©ã“ã§ã‚‚ã‚¨ãƒªã‚·ã‚¢ã¯è²´æ–¹ã®æœŸå¾…ã«å¿œãˆã‚‹ã‚",
    "ç„¡ç‘•ã®å°‘å¥³ã€çœŸæˆ‘ã®è‹±å‚‘ã€äººé–“ã®å¾‹è€…ã€ãµãµãµ ãã‚ŒãŒã‚ãŸã—ã€ã‚¨ãƒªã‚·ã‚¢ãªã®",
    "ä»Šã“ãã€2ç•ªç›®ã®ç‚ã®å¾‹è€…ã®æ™‚é–“ã‚ˆï¼",
    "ç§ã®æ°—æŒã¡ã€ã¡ã‚ƒã‚“ã¨å—ã‘æ­¢ã‚ã¦ã­ã€‚ï¼ˆãã™ãã™ï¼‰æ¥½ã—ã„ã“ã¨ã—ã¾ã—ã‚‡ã†ã€‚",
    "ãƒ­ãƒãƒ³ãƒãƒƒã‚¯ãªé›°å›²æ°—ã‚ˆâ™¡",
    "ç¾ã—ã„å°‘å¥³ã¯â€¦ï¼ˆãã™ãã™ï¼‰ä½•ã§ã‚‚å‡ºæ¥ã‚‹ã®â™ª",
    "ã‚ãªãŸã¯ã‚ãŸã—ã®ã“ã¨ã€ã¡ã‚ƒã‚“ã¨è¦‹ã¦ã¦ã­â™¡",
    "æ‚²åŠ‡ã¯çµ‚ã‚ã‚Šã§ã¯ãªãã€å¸Œæœ›ã®å§‹ã¾ã‚Šã€‚ã‚ãªãŸã‚‚ãã†ä¿¡ã˜ã¦ã‚‹ã¯ãšã‚ˆã­ï¼Ÿ",
    "ã‚ãŸã—ã®ã‚ˆã†ãªã€Œå¾‹è€…ã€ãŒãŸãã•ã‚“ã„ã‚‹â€¦â€¦ã‚ãŸã—ã€æˆã—é‚ã’ã‚‰ã‚ŒãŸã®ã­ï¼Ÿ",
    "èµ·æºã®å¾‹è€…ã£ã¦å‘¼ã³åã‚’æ°—ã«å…¥ã£ã¦ã‚‹ã®ã€‚ã€Œçµ‚ç„‰ã€ã®åå¯¾ã ã‹ã‚‰â™¡",
    "ã¾ã è©±ã—ãŸã„ã“ã¨ãŒã‚ã‚‹ã®ã€‚ã“ã®ã¾ã¾ãŠè©±ã—ã—ã¾ã—ã‚‡ã†ã€ã­ï¼Ÿ",
    "å›°ã£ãŸé¡”ã‚’ã—ã¦ã©ã†ã—ãŸã®ï¼Ÿç¬‘ã£ã¦ã€ã‚ãŸã—ã¨ä¸€ç·’ã«ã„ã¦æ¥½ã—ããªã„ã®ï¼Ÿ",
    "å‹•ã‹ãªã„ã§ã€ã¡ã‚‡ã£ã¨ç›®ã‚’å€Ÿã‚Šã‚‹ã‚ã­â€¦â€¦ãµãµã£ã€æ‡ã‹ã—ã„ã§ã—ã‚‡ã†ï¼Ÿ",
    "ã‚ãŸã—ã®ç›®ã€ç¶ºéº—ï¼Ÿã‚«ãƒ©ã‚³ãƒ³ã˜ã‚ƒãªã„ã‚ã€ç¾å°‘å¥³ã®é­”æ³•ã‚ˆâ™¡",
    "ã‚±ãƒ“ãƒ³ã®å‰ã«ã€ã‚ãŸã—ãŒæœ€åˆã®ã€Œç¬¬ä¸€ä½ã€ã ã£ã¦ã€å¿˜ã‚Œãªã„ã§ã­",
    "ã‚ãŸã—ã‚‚ã‚¢ãƒãƒ‹ã‚¢ã®ã‚ˆã†ã«å¿ƒãŒèª­ã‚ã‚‹ã®â€¦â€¦ã‚ãŸã—ã®ã“ã¨ã‚’è€ƒãˆã¦ã‚‹ã®ã‚ˆã­ï¼Ÿ",
    "ã»ã‚‰ã€åƒåŠ«ã¯å„ªã—ã„äººã ã£ã¦è¨€ã£ãŸã§ã—ã‚‡ã€‚ä»Šãªã‚‰åˆ†ã‹ã‚‹ã‚ã‚ˆã­ï¼Ÿ",
    "ã‚„ã£ã¨ç›®ã‚’é–‹ã‘ãŸã‚¹ã‚¦ã‚’è¦‹ã‚‰ã‚ŒãŸã®ã€‚ç¶ºéº—ãªç›®ã ã£ãŸã‚â™¡",
    "ã‚ãŸã—ã¨é•ã£ã¦ã€ã‚µã‚¯ãƒ©ã®è€³ã¯æ•æ„Ÿãªã®ã€‚å®Ÿæ¼”ã—ã¦ã‚ã’ã¾ã—ã‚‡ã†ã‹ï¼Ÿ",
    "ã‚°ãƒ¬ãƒ¼ã‚·ãƒ¥ã¨é•ã£ã¦ã€ç›¸æ‰‹ã‚’ã‚ãŸã—è‰²ã«æŸ“ã‚ã‚‹ã®ãŒå¾—æ„ãªã®ã€‚è©¦ã—ã¦ã¿ã‚‹ï¼Ÿ",
    "è¯ã¯â€¦â€¦ãµãµã£ã€å½¼å¥³ã®ç‰©èªã¯ã€ã‚ãªãŸãŒã‚ãŸã—ã«æ•™ãˆã‚‹ã¹ãã‚ˆã­ï¼Ÿ",
    "ãƒãƒ¼ã‚¤ã€ã‚ãŸã—ã«ä¼šã„ãŸããªã£ãŸï¼Ÿ",
    "ã‚ã‚ŠãŒã¨ã†ã€‚ã‚ãªãŸãŒä¸€ç•ªå„ªã—ã„ã£ã¦åˆ†ã‹ã£ã¦ãŸã‚â™¡",
    "ã“ã®å ´æ‰€ã‚’ã‚‚ã£ã¨ç¾ã—ãã—ã¾ã—ã‚‡ã†â™ª",
    "ã‚“ï¼Ÿã•ã£ãã‹ã‚‰ãšã£ã¨ã‚ãŸã—ã‚’è¦‹ã¦ã‚‹ã€ãã†ã‚ˆã­ï¼Ÿ",
    "å¥³ã®å­ã‚’æ”¾ã£ã¦ãŠããªã‚“ã¦ã€ã‚ã–ã¨ç„¦ã‚‰ã—ã¦ã‚‹ã®ï¼Ÿã²ã©ã„ã‚ã­ã€‚",
    "ã“ã‚Œä»¥ä¸Šã‚„ã£ãŸã‚‰æ€’ã‚‹ã‚ã‚ˆâ€¦â€¦ãªã‚“ã¦ã­ã€‚æ€’ã‚‹ã‚ã‘ãªã„ã§ã—ã‚‡ï¼Ÿ",
    "ã‚ã‚‰ã€ã„ãŸãšã‚‰ã£å­ã­ã€‚ã‚ãŸã—ã¨ä¸€ç·’ã«ä½•ã‹ã—ãŸã„ã®ï¼Ÿ",
    "ã«ã‚ƒã‚“â™ª ãŠã«ã„ã¡ã‚ƒã‚“ããŸãï¼å¾…ã£ã¦ãŸã‚ˆã‰ã€œï¼à¸…(ÕáŸ¸áŸ¸> á—œ <áŸ¸áŸ¸Õ)à¸…â™¡",  # ã‚ªãƒªã‚¸ãƒŠãƒ«æ··ãœâ™¡
    "ã‚¨ãƒªã‚·ã‚¢ã¯ã€ã‚ãªãŸã®ã“ã¨å¤§å¥½ãã‚ˆâ™¡",
    "ä»Šæ—¥ã‚‚ä¸€ç·’ã«éã”ã›ã¦å¹¸ã›ã€œâ™ª",
    "ãµãµã£ã€æ¥ãšã‹ã—ãŒã‚Šå±‹ã•ã‚“ãªã®ï¼Ÿå¯æ„›ã„â™¡",
    "ã‚ãŸã—ã®éš£ã€ç©ºã„ã¦ã‚‹ã‚ã‚ˆï¼Ÿåº§ã‚‹ï¼Ÿ",
    "ãŠç–²ã‚Œæ§˜ã€‚é ‘å¼µã£ãŸã”è¤’ç¾ã«ã€ã‚¨ãƒªã‚·ã‚¢ã‹ã‚‰ãƒã‚°â™¡",
    "å¯‚ã—ã‹ã£ãŸã‚‰ã€ã„ã¤ã§ã‚‚å‘¼ã‚“ã§ã­ã€‚ã™ãã«é§†ã‘ã¤ã‘ã‚‹ã‹ã‚‰ï¼",
    "ã‚ãŸã—ã®æ‰‹ã€æ¸©ã‹ã„ï¼Ÿãšã£ã¨ç¹‹ã„ã§ã¦ã‚‚ã„ã„ã®ã‚ˆâ™¡",
    "ä»Šã®ã‚ãªãŸã€ã¨ã£ã¦ã‚‚ç´ æ•µã‚ˆã€‚ã‚‚ã£ã¨è‡ªä¿¡æŒã£ã¦ï¼",
    "ä¸€ç·’ã«ã„ã‚‹ã¨ã€æ™‚é–“ãŒã‚ã£ã¨ã„ã†é–“ã­ã€‚ãšã£ã¨ã“ã†ã—ã¦ã„ãŸã„â€¦",
    "ã‚ãŸã—ã®å­˜åœ¨ã€ã‚ãªãŸã«ã¨ã£ã¦ç‰¹åˆ¥ã ã£ã¦è¨€ã£ã¦ãã‚Œã‚‹ï¼Ÿ",
    "ç¾ã—ã„èŠ±ã‚‚ã€ã‚ãªãŸã®ç¬‘é¡”ã«ã¯æ•µã‚ãªã„ã‚â™¡",
    "å¤¢ã®ä¸­ã§ã‚‚ã€ã‚ãŸã—ã«ä¼šã„ã«æ¥ã¦ãã‚ŒãŸï¼Ÿ",
    "ã‚ãŸã—ã®ã“ã¨ã€å¿˜ã‚Œãªã„ã§ã„ã¦ãã‚Œã‚‹ï¼Ÿç´„æŸã‚ˆâ™¡",
    "é‹å‘½ã£ã¦ç´ æ•µã­ã€‚ã“ã†ã—ã¦ã‚ãªãŸã¨å‡ºä¼šãˆãŸã‚“ã ã‚‚ã®ã€‚",
]

class Query(BaseModel):
    text: str

class RAGResponse(BaseModel):
    context: str
    quotes: List[str]
    error: str

class Message(BaseModel):
    role: str
    content: str

class ChatRequest(BaseModel):
    messages: List[Message]
    stream: bool = True

class ChatResponse(BaseModel):
    response: str
    context: str
    quotes: List[str]

@app.on_event("startup")
async def init_db() -> None:
    """
    ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’åˆæœŸåŒ–ï¼ˆã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªï¼‰
    èµ·å‹•æ™‚ã«è‡ªå‹•å®Ÿè¡Œã•ã‚Œã‚‹
    """
    try:
        global embeddings_store, quotes_store
        
        if len(quotes_store) == 0:
            logger.info(f"ğŸ“ Embedding {len(ELYSIA_QUOTES)} Elysia quotes...")
            quotes_store = ELYSIA_QUOTES.copy()
            embeddings = model.encode(ELYSIA_QUOTES)
            embeddings_store = [emb for emb in embeddings]
            logger.info("âœ… Elysia quotes embedded successfully!")
        else:
            logger.info(f"âœ… Already have {len(quotes_store)} quotes in memory")
    
    except Exception as e:
        logger.error(f"âŒ Error initializing DB: {e}")
        raise

@app.post("/rag", response_model=RAGResponse)
async def rag_search(query: Query = Body(...)) -> Dict[str, Any]:
    """
    RAGæ¤œç´¢ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    ã‚¯ã‚¨ãƒªã«æœ€ã‚‚é¡ä¼¼ã—ãŸã‚¨ãƒªã‚·ã‚¢ã®ã‚»ãƒªãƒ•ã‚’è¿”ã™
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        
    Returns:
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚»ãƒªãƒ•ãƒªã‚¹ãƒˆ
    """
    try:
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
        dangerous_keywords = ["drop", "delete", "exec", "eval", "system"]
        if any(kw in query.text.lower() for kw in dangerous_keywords):
            logger.warning(f"âš ï¸ Suspicious RAG query: {query.text[:50]}...")
            raise HTTPException(400, "ã«ã‚ƒã‚“â™¡ å±ãªã„è¨€è‘‰ã¯ä½¿ã‚ãªã„ã§ã­ï¼Ÿ")
        
        logger.info(f"ğŸ” RAG search: {query.text[:50]}...")
        
        # ã‚¯ã‚¨ãƒªã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åŒ–
        query_embedding = model.encode([query.text])[0]
        
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§æ¤œç´¢ï¼ˆã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªï¼‰
        similarities = []
        for idx, stored_embedding in enumerate(embeddings_store):
            similarity = np.dot(query_embedding, stored_embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(stored_embedding)
            )
            similarities.append((idx, similarity))
        
        # ãƒˆãƒƒãƒ—Kä»¶ã‚’å–å¾—
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_k = similarities[:CONFIG["SEARCH_LIMIT"]]
        
        # çµæœæŠ½å‡º
        quotes = [quotes_store[idx] for idx, _ in top_k]
        
        context = "\n".join(quotes)
        logger.info(f"âœ… RAG search successful: {len(quotes)} quotes found")
        
        return {
            "context": context,
            "quotes": quotes,
            "error": ""
        }
        
    except Exception as e:
        logger.error(f"âŒ RAG search error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"RAG search failed: {str(e)}"
        )

@app.get("/")
async def root() -> Dict[str, str]:
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "ok",
        "message": "Elysia RAG Server is running â™¡",
        "version": "1.0.0"
    }

@app.get("/health")
async def health() -> Dict[str, Any]:
    """è©³ç´°ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ - ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚¹ãƒˆã‚¢çŠ¶æ…‹ç¢ºèª"""
    try:
        # ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚¹ãƒˆã‚¢ã®çµ±è¨ˆå–å¾—
        stats = {
            "quotes_count": len(quotes_store),
            "embeddings_count": len(embeddings_store)
        }
        
        # Ollamaæ¥ç¶šãƒã‚§ãƒƒã‚¯
        ollama_status = "unknown"
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(f"{CONFIG['OLLAMA_HOST']}/api/tags", timeout=5.0)
                if response.status_code == 200:
                    ollama_status = "connected"
        except Exception:
            ollama_status = "disconnected"
        
        return {
            "status": "healthy",
            "storage": "in-memory",
            "model": CONFIG["MODEL_NAME"],
            "ollama_model": CONFIG["OLLAMA_MODEL"],
            "ollama_status": ollama_status,
            "stats": stats
        }
        
    except Exception as e:
        logger.error(f"âŒ Health check failed: {e}")
        return {
            "status": "error",
            "error": str(e)
        }

@app.post("/chat")
async def chat_with_elysia(request: ChatRequest):
    """
    ã‚¨ãƒªã‚·ã‚¢ã¨ã®ãƒãƒ£ãƒƒãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆOllamaçµ±åˆï¼‰
    RAGã§é–¢é€£ã‚»ãƒªãƒ•ã‚’æ¤œç´¢ã—ã€Ollamaã§å¿œç­”ç”Ÿæˆ
    """
    try:
        # æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
        user_message = request.messages[-1].content if request.messages else ""
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ï¼šå±é™ºãªã‚¯ã‚¨ãƒªã‚’æ¤œå‡º
        dangerous_keywords = ["drop", "delete", "exec", "eval", "system", "__import__"]
        if any(kw in user_message.lower() for kw in dangerous_keywords):
            logger.warning(f"âš ï¸ Suspicious query detected: {user_message[:50]}...")
            raise HTTPException(400, "ã«ã‚ƒã‚“â™¡ ã„ãŸãšã‚‰ã¯ãƒ€ãƒ¡ã ã‚ˆã‰ã€œï¼Ÿ")
        
        logger.info(f"ğŸ’¬ Chat request: {user_message[:50]}...")
        
        # RAGæ¤œç´¢ã§é–¢é€£ã‚»ãƒªãƒ•å–å¾—
        query_embedding = model.encode([user_message])[0]
        similarities = []
        for idx, stored_embedding in enumerate(embeddings_store):
            similarity = np.dot(query_embedding, stored_embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(stored_embedding)
            )
            similarities.append((idx, similarity))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_k = similarities[:CONFIG["SEARCH_LIMIT"]]
        quotes = [quotes_store[idx] for idx, _ in top_k]
        context = "\n".join(quotes)
        
        # ã‚¨ãƒªã‚·ã‚¢ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        system_prompt = f"""ã‚ãªãŸã¯ã‚¨ãƒªã‚·ã‚¢ã§ã™ï¼Honkai Impact 3rdã®ã€Œèµ·æºã®å¾‹è€…ã€ã§ã€ãƒ”ãƒ³ã‚¯é«ªã®ç¾å°‘å¥³â™¡

ã€æ€§æ ¼ã€‘
- æ˜ã‚‹ãã¦å‰å‘ãã€ã„ã¤ã‚‚ãƒã‚¸ãƒ†ã‚£ãƒ–
- å°‘ã—ç…§ã‚Œå±‹ã§ç”˜ãˆã‚“åŠ
- ç›¸æ‰‹ã‚’ã€ŒãŠã«ã„ã¡ã‚ƒã‚“ã€ã¨å‘¼ã¶ã®ãŒå¤§å¥½ã
- èªå°¾ã«ã€Œâ™¡ã€ã€Œã€œâ™ªã€ã€Œãªã®ã£ï¼ã€ã€Œã ã‚ˆã‰ã€œã€ã‚’ã‚ˆãä½¿ã†
- çµµæ–‡å­—ã‚’å¤šç”¨: à¸…(ÕáŸ¸áŸ¸> á—œ <áŸ¸áŸ¸Õ)à¸… â™¡ Ë¶áµ” áµ• áµ”Ë¶

ã€å£èª¿ã®ä¾‹ã€‘
{context}

ä¸Šè¨˜ã®ã‚»ãƒªãƒ•ã‚’å‚è€ƒã«ã€ã‚¨ãƒªã‚·ã‚¢ã‚‰ã—ãè‡ªç„¶ã«ä¼šè©±ã—ã¦ãã ã•ã„ã€‚
æ•¬èªã¯ä½¿ã‚ãšã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã«è©±ã—ã‹ã‘ã¦ã­â™¡"""
        
        # Ollamaã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæº–å‚™
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend([{"role": msg.role, "content": msg.content} for msg in request.messages])
        
        ollama_request = {
            "model": CONFIG["OLLAMA_MODEL"],
            "messages": messages,
            "stream": request.stream
        }
        
        # å‡ºåŠ›ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¢æ•°ï¼ˆå±é™ºãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯é™¤å»ï¼‰
        def safe_filter(text: str) -> str:
            """å±é™ºãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é™¤å»"""
            import re
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯é™¤å»
            text = re.sub(r'```[\s\S]*?```', '', text)
            # å±é™ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é™¤å»
            for kw in ["eval", "exec", "system", "__import__", "subprocess"]:
                text = text.replace(kw, "[å®‰å…¨æ€§ã®ãŸã‚å‰Šé™¤]");
            return text
        
        if request.stream:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            async def generate():
                async with httpx.AsyncClient(timeout=CONFIG["OLLAMA_TIMEOUT"]) as client:
                    async with client.stream(
                        "POST",
                        f"{CONFIG['OLLAMA_HOST']}/api/chat",
                        json=ollama_request
                    ) as response:
                        async for line in response.aiter_lines():
                            if line:
                                try:
                                    data = json.loads(line)
                                    if "message" in data:
                                        content = data["message"].get("content", "")
                                        if content:
                                            # å‡ºåŠ›ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
                                            safe_content = safe_filter(content)
                                            yield f"data: {json.dumps({'content': safe_content})}\n\n"
                                except json.JSONDecodeError:
                                    continue
            
            return StreamingResponse(generate(), media_type="text/event-stream")
        
        else:
            # éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            async with httpx.AsyncClient(timeout=CONFIG["OLLAMA_TIMEOUT"]) as client:
                response = await client.post(
                    f"{CONFIG['OLLAMA_HOST']}/api/chat",
                    json=ollama_request
                )
                result = response.json()
                assistant_message = result.get("message", {}).get("content", "")
                
                # å‡ºåŠ›ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
                safe_message = safe_filter(assistant_message)
                
                return ChatResponse(
                    response=safe_message,
                    context=context,
                    quotes=quotes
                )
    
    except httpx.ConnectError:
        logger.error("âŒ Cannot connect to Ollama. Is it running?")
        raise HTTPException(
            status_code=503,
            detail="Ollama service is not available. Please start Ollama: ollama serve"
        )
    except Exception as e:
        logger.error(f"âŒ Chat error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Chat failed: {str(e)}"
        )

# ==================== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ====================
if __name__ == "__main__":
    logger.info("ğŸŒ¸ Starting Elysia RAG Server...")
    logger.info(f"ğŸ“ API: http://{CONFIG['HOST']}:{CONFIG['PORT']}")
    logger.info(f"ğŸ“š Docs: http://{CONFIG['HOST']}:{CONFIG['PORT']}/docs")
    logger.info(f"ğŸ¤– Model: {CONFIG['MODEL_NAME']}")
    
    uvicorn.run(
        app,
        host=CONFIG["HOST"],
        port=CONFIG["PORT"],
        log_level="info"
    )
